{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import errno\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time as tm\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_columns = 100\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import PyPDF2\n",
    "import plotly as py\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS S3 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(file_name):\n",
    "    fs = s3fs.S3FileSystem(profile_name = 'dmitry.zorikhin@XXX')\n",
    "    df = pd.read_csv(fs.open(f'discover.energy-datasource/XXX/{file_name}'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_df = get_df('assets.csv')\n",
    "\n",
    "basins_df = get_df('basins.csv')\n",
    "\n",
    "assets_basins_df = assets_df.merge(basins_df, left_on=['basin_id'], \n",
    "                                   right_on=['id'], how='left', suffixes=('', '_basin'))\n",
    "\n",
    "asset_production_df = get_df('asset_quarterly_data.csv')\n",
    "\n",
    "assets_basins_dataset = asset_production_df.merge(assets_basins_df, left_on=['asset_id'], \n",
    "                                                  right_on=['id'], how='left', \n",
    "                                                  suffixes=('', '_asset'))\n",
    "(assets_basins_dataset\n",
    " .loc[(assets_basins_dataset.name_basin == 'ETX/Haynesville'),\n",
    "      'name_basin']) = 'East TX Haynesville' \n",
    "\n",
    "asset_data_df = get_df('asset_metrics_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(assets_basins_dataset.name_basin.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "BASIN_NAME = 'Permian'\n",
    "PERMIAN_TYPE = ''\n",
    "\n",
    "\"\"\"Permian should be divided in 3 parts which will be set as parameters:\n",
    "large_diversified_ - big companies\n",
    "us_oil_ - medium size companies\n",
    "micro_cap_ - small size companies\n",
    "Underscore is needed for proper file name\n",
    "For now this script should be executed 3 times for each parameter until company level section\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if BASIN_NAME == 'Permian':\n",
    "    PERMIAN_TYPE = 'us_oil_'\n",
    "    \n",
    "    large_diversified = ['APA', 'COP', 'EOG', 'MRO', 'NBL', 'OXY', 'PXD', 'XOM']\n",
    "    us_oil = ['CXO', 'DVN', 'FANG', 'MTDR', 'OVV', 'PDCE', 'PE', 'SM', 'WPX', 'XEC']\n",
    "    micro_cap = ['CDEV', 'CPE', 'OAS', 'QEP']\n",
    "    \n",
    "    assets_basins_dataset = assets_basins_dataset[(assets_basins_dataset.ticker.isin(us_oil))]\n",
    "    assets_count = (assets_basins_dataset[(assets_basins_dataset.name_basin == 'Permian') \n",
    "                                          & (assets_basins_dataset.ticker.isin(us_oil))]\n",
    "                    .asset_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_PERIOD = '2020_Q1'\n",
    "START_QUARTER_ACTUAL = 20192\n",
    "END_QUARTER_ACTUAL = 20201\n",
    "START_QUARTER_FORECAST = 20202\n",
    "END_QUARTER_FORECAST = 20212\n",
    "COLORS = [\n",
    "    '#91bd3a', '#64c4ed', '#5f6caf', '#cfb495', '#deff8b',\n",
    "    '#faafff', '#b9cced', '#347474', '#be8abf', '#fddb3a',\n",
    "    '#e58a8a', '#75b79e', '#7f78d2', '#f1935c', '#d9bf77',\n",
    "    '#50bda1', '#ffd082', '#35495e', '#7fa998', '#a8d3da'\n",
    "] * 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = datetime.now().strftime('%d-%m-%Y')\n",
    "TODAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../reports/{REPORT_PERIOD}'\n",
    "\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(f'{path}/{BASIN_NAME}/')\n",
    "    print(f'Folders {REPORT_PERIOD} and {REPORT_PERIOD}/{BASIN_NAME} created')\n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print(f'Folder {REPORT_PERIOD} already exists')\n",
    "    try:\n",
    "        os.mkdir(f'{path}/{BASIN_NAME}/')\n",
    "        print(f'Folder {REPORT_PERIOD}/{BASIN_NAME} created')\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            print(f'Folder {REPORT_PERIOD}/{BASIN_NAME} already exists')\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f'{path}/{BASIN_NAME}/pdf')\n",
    "    print(f'Folder {REPORT_PERIOD}/{BASIN_NAME}/pdf created')\n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print(f'Folder {REPORT_PERIOD}/{BASIN_NAME}/pdf already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter per basin and company function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_for_analysis_basin_level(prepared_dataset, parameter, name_basin='', \n",
    "                                     aggregate='sum', aggregate_basis='basin', \n",
    "                                     start_quarter='', end_quarter=''):\n",
    "    \"\"\"Inputs:\n",
    "    prepared_dataset - assets_basins_dataset as default, prepared above\n",
    "    parameter - values to analyse (assets_basins_dataset columns)\n",
    "    name_basin - basin name to analyse, default is data for all basins\n",
    "    aggregate - sum as default\n",
    "    aggregate_basis - aggregation basen on basin level or company level in result dataset\n",
    "    start_quarter - choose start quarter for analysis, default value is empty (no restriction \n",
    "    to start quarter)\n",
    "    end_quarter - choose end quarter for analysis, default value is empty (no restriction \n",
    "    to end quarter)\n",
    "    \n",
    "    Return:\n",
    "    pivot table with aggregates for parameter across basin(s) or companies with or without \n",
    "    timeline restriction\n",
    "    \n",
    "    \"\"\"\n",
    "    df = (prepared_dataset\n",
    "          .groupby(['name_basin', 'quarter', 'ticker', 'name'])\n",
    "          .agg({parameter: aggregate})\n",
    "          .reset_index())\n",
    "    \n",
    "    if name_basin != '':\n",
    "        df = df[df['name_basin'] == name_basin]\n",
    "    \n",
    "    if start_quarter != '' and end_quarter != '':\n",
    "        df = df[(df['quarter'] >= start_quarter) & (df['quarter'] <= end_quarter)]\n",
    "    \n",
    "    if aggregate_basis == 'company':\n",
    "        df_pivot = pd.pivot_table(df, index=['ticker', 'name_basin', 'name'], \n",
    "                                  columns='quarter', values=parameter)\n",
    "    else:\n",
    "        df_pivot = pd.pivot_table(df, index=['name_basin', 'ticker', 'name'], \n",
    "                                  columns='quarter', values=parameter)\n",
    "    \n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pie_plot_settings(df, column, title, path):\n",
    "    \n",
    "    data = [{ 'type': \"pie\", \n",
    "              'labels': df['Company'].tolist(), \n",
    "              'values': df[column].tolist(),\n",
    "              'textinfo': 'value'\n",
    "            }]\n",
    "    layout = { 'title': title,\n",
    "               'legend': {'orientation': 'h', 'xanchor': 'center', 'x': 0.5},\n",
    "               'colorway': COLORS,\n",
    "               'height': 600}\n",
    "    \n",
    "    if '/' in title:\n",
    "        title = title.replace('/', ' per ')\n",
    "        \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {str(layout)};\\n'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_bar_chart_settings(df, column, title, path):\n",
    "    \n",
    "    data = [{ 'type': 'bar',\n",
    "              'x': df['asset_name'].tolist(), \n",
    "              'y': df[column].tolist()\n",
    "            }]\n",
    "    layout = { 'xaxis': {'title': 'Basin Assets', 'automargin': True},\n",
    "               'title': title,\n",
    "               'yaxis': {'title': column, 'ticks': 'outside'},\n",
    "               'colorway': COLORS,\n",
    "               'height': 800}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bubble_chart_settings(df, title, path):\n",
    "    \n",
    "    hover_text = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        hover_text.append(('Company: {ticker}<br>'\n",
    "                          'Asset Name: {name}<br>'\n",
    "                          'Capex ($MM): {capex}<br>'\n",
    "                          'Net Production (Mboe/d): {net_prod}<br>').format(\n",
    "                                                ticker=row['ticker'],\n",
    "                                                name=row['name'],\n",
    "                                                capex=row['Capex ($MM)'],\n",
    "                                                net_prod=row['Net Production (Mboe/d)']))    \n",
    "    \n",
    "    df['text'] = hover_text\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for ticker in df.ticker.unique():\n",
    "        data.append(\n",
    "            {'type': 'scatter',\n",
    "             'name': ticker,\n",
    "              'x': df[df['ticker'] == ticker]['Capex ($MM)'].tolist(), \n",
    "              'y': df[df['ticker'] == ticker]['Net Production (Mboe/d)'].tolist(),\n",
    "              'mode': 'markers',\n",
    "              'marker': {'size': 30},\n",
    "             'hoverinfo': 'text',\n",
    "             'hovertext': df[df['ticker'] == ticker]['text'].tolist()\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    layout = { 'xaxis': {'title': 'Net Capex ($MM)'},\n",
    "               'title': title,\n",
    "               'yaxis': {'title': 'Net Production (Mboe/d)'},\n",
    "               'legend': {'itemclick': 'toggleothers', 'itemdoubleclick': 'toggle'},\n",
    "               'colorway': COLORS,\n",
    "               'height': 700}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_stack_bar_chart_settings(df, title, path):\n",
    "    \n",
    "    data = [{'type': 'bar',\n",
    "             'name': BASIN_NAME,\n",
    "             'y': df['Company'].tolist(),\n",
    "             'x': df[f'{BASIN_NAME}_p'].tolist(),          \n",
    "             'orientation': 'h'},\n",
    "            {'type': 'bar',\n",
    "             'name': 'Other basins',\n",
    "             'y': df['Company'].tolist(),\n",
    "             'x': df['Other_basins_p'].tolist(),          \n",
    "             'orientation': 'h'}]\n",
    "\n",
    "    layout = { 'barmode': 'stack',\n",
    "               'title': title,\n",
    "               'xaxis': {'tickformat': '.0%', 'ticks': 'outside'},\n",
    "               'yaxis': {'autorange': 'reversed', 'ticks': 'outside'},\n",
    "               'legend': {'orientation': 'h', 'x': 0.35, 'itemclick': 'toggleothers', \n",
    "                          'itemdoubleclick': 'toggle'},\n",
    "               'colorway': COLORS,\n",
    "               'height': 600}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {str(layout)};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(hex_color: str):\n",
    "    \n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    if len(hex_color) == 3:\n",
    "        hex_color = hex_color * 2\n",
    "        \n",
    "    return int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_chart_settings(df, title, type_hc, path, parameter=''):  # Stacked\n",
    "    \n",
    "    # Check if all values are zeros, do not need to display the chart\n",
    "    if df.iloc[:, 1:].sum().values.sum() == 0: \n",
    "        return ('data : none')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    assets = df.columns[1:].tolist()\n",
    "    assets_max_value_name = max([len(item) for item in assets])\n",
    "    assets_number = len(df.columns[1:].tolist())\n",
    "    \n",
    "    if parameter == 'general' and assets_max_value_name >= 38:\n",
    "        fontsize = 9\n",
    "    elif parameter == 'general' and assets_max_value_name > 32 and assets_max_value_name < 38:\n",
    "        fontsize = 11\n",
    "    else:\n",
    "        fontsize = 12\n",
    "\n",
    "    for asset_id in range(assets_number):\n",
    "        data.append(\n",
    "            {'type': 'scatter',\n",
    "             'name': assets[asset_id],\n",
    "             'y': df[assets[asset_id]].tolist(),\n",
    "             'x': list(range(len(df['quarter']))),\n",
    "             'hoverinfo': 'name+x+y',\n",
    "              'mode': 'lines',\n",
    "             'line': {'width': 0.1},\n",
    "             'fillcolor': f'rgba{(*hex_to_rgb(COLORS[asset_id]), 1.0)}',\n",
    "             'stackgroup': 'one'}\n",
    "        )\n",
    "    \n",
    "    if type_hc == 'oil':\n",
    "        y_axis_label = 'MMbbl/d'\n",
    "    elif type_hc == 'gas':\n",
    "        y_axis_label = 'MMcf/d'\n",
    "    \n",
    "    if BASIN_NAME == 'Permian' and parameter == 'general' and assets_count > 26:\n",
    "        layout = { 'title': title,\n",
    "                   'xaxis': {'title': 'Quarter', 'ticks': 'outside', 'tickmode': 'array', \n",
    "                             'tickvals': list(range(len(df['quarter']))), \n",
    "                             'ticktext': xlabels_format(df), 'ticklen': 8},\n",
    "                   'yaxis': {'ticks': 'outside', 'title': {'text': y_axis_label, 'standoff': 15}},\n",
    "                   'legend': {'orientation': 'v', 'itemclick': 'toggleothers', \n",
    "                              'itemdoubleclick': 'toggle'},\n",
    "                   'colorway': COLORS,\n",
    "                   'height': 900}\n",
    "        \n",
    "        fig = go.Figure(data=data, layout={ 'title': title,\n",
    "                                            'xaxis': {'title': 'Quarter', 'ticks': 'outside', \n",
    "                                                      'tickmode': 'array', \n",
    "                                                      'tickvals': list(range(len(df['quarter']))), \n",
    "                                                      'ticktext': xlabels_format(df), \n",
    "                                                      'ticklen': 8},\n",
    "                                            'yaxis': {'ticks': 'outside', \n",
    "                                                      'title': {'text': y_axis_label, \n",
    "                                                                'standoff': 15}},                                            \n",
    "                                            'colorway': COLORS,\n",
    "                                            'showlegend': False,\n",
    "                                            'height': 700})\n",
    "        fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "        \n",
    "    else:        \n",
    "        layout = {'title': title,\n",
    "                  'xaxis': {'title': 'Quarter', 'ticks': 'outside', 'tickmode': 'array', \n",
    "                            'tickvals': list(range(len(df['quarter']))), \n",
    "                            'ticktext': xlabels_format(df), 'ticklen': 8},\n",
    "                  'yaxis': {'ticks': 'outside', 'title': {'text': y_axis_label, 'standoff': 15}},\n",
    "                  'showlegend': True,\n",
    "                  'legend': {'orientation': 'h', 'itemclick': 'toggleothers', \n",
    "                             'itemdoubleclick': 'toggle', 'xanchor': 'center', \n",
    "                             'x': 0.5, 'y': -0.11},\n",
    "                  'colorway': COLORS,\n",
    "                  'height': 900}\n",
    "        \n",
    "        fig = go.Figure(data=data, layout={'title': title,\n",
    "                                           'xaxis': {'title': 'Quarter', 'ticks': 'outside', \n",
    "                                                     'tickmode': 'array', \n",
    "                                                     'tickvals': list(range(len(df['quarter']))), \n",
    "                                                     'ticktext': xlabels_format(df), \n",
    "                                                     'ticklen': 8},\n",
    "                                           'yaxis': {'ticks': 'outside', \n",
    "                                                     'title': {'text': y_axis_label, \n",
    "                                                               'standoff': 15}},\n",
    "                                           'showlegend': True,\n",
    "                                           'legend': {'font': {'size': fontsize}, \n",
    "                                                      'orientation': 'h', \n",
    "                                                      'itemclick': 'toggleothers', \n",
    "                                                      'itemdoubleclick': 'toggle', \n",
    "                                                      'xanchor': 'center', 'x': 0.5, 'y': -0.11},\n",
    "                                           'colorway': COLORS,\n",
    "                                           'height': 900})\n",
    "        fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_bar_chart_settings(df, title, type_values, path, parameter=''):\n",
    "    \n",
    "    if df.iloc[:, 1:].sum().values.sum() == 0:\n",
    "        return ('data : none')\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    assets = df.columns[1:].tolist()\n",
    "    assets_max_value_name = max([len(item) for item in assets])\n",
    "    assets_number = len(df.columns[1:].tolist())\n",
    "    \n",
    "    if parameter == 'general' and assets_max_value_name >= 38:\n",
    "        fontsize = 9\n",
    "    elif parameter == 'general' and assets_max_value_name > 32 and assets_max_value_name < 38:\n",
    "        fontsize = 11\n",
    "    else:\n",
    "        fontsize = 12\n",
    "\n",
    "    for asset_id in range(assets_number):\n",
    "        data.append(\n",
    "            {'type': 'bar',\n",
    "             'name': assets[asset_id],\n",
    "             'y': df[assets[asset_id]].tolist(),\n",
    "             'x': list(range(len(df['quarter']))),\n",
    "             'hoverinfo': 'name+y'}\n",
    "        )\n",
    "    \n",
    "    if type_values == 'rig':\n",
    "        y_axis_label = 'Active rigs'\n",
    "    elif type_values == 'well':\n",
    "        y_axis_label = 'New Wells Brought Online'\n",
    "    elif type_values == 'capex':\n",
    "        y_axis_label = '$MM'\n",
    "\n",
    "    if BASIN_NAME == 'Permian' and parameter == 'general' and assets_count > 26:\n",
    "        layout = { 'barmode': 'stack',\n",
    "                   'title': title,\n",
    "                   'xaxis': {'title': 'Quarter', 'ticks': 'outside', 'tickmode': 'array', \n",
    "                             'tickvals': list(range(len(df['quarter']))), \n",
    "                             'ticktext': xlabels_format(df), 'ticklen': 8},\n",
    "                   'yaxis': {'ticks': 'outside', 'title': y_axis_label},\n",
    "                   'legend': {'orientation': 'v', 'itemclick': 'toggleothers', \n",
    "                              'itemdoubleclick': 'toggle'},\n",
    "                   'colorway': COLORS,\n",
    "                   'height': 900 }\n",
    "        \n",
    "        fig = go.Figure(data=data, layout={ 'barmode': 'stack',\n",
    "                                            'title': title,\n",
    "                                            'xaxis': {'title': 'Quarter', 'ticks': 'outside', \n",
    "                                                      'tickmode': 'array', \n",
    "                                                      'tickvals': list(range(len(df['quarter']))), \n",
    "                                                      'ticktext': xlabels_format(df), \n",
    "                                                      'ticklen': 8},\n",
    "                                            'yaxis': {'ticks': 'outside', 'title': y_axis_label},                                            \n",
    "                                            'colorway': COLORS,\n",
    "                                            'showlegend': False,\n",
    "                                            'height': 700 })\n",
    "        fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    else:    \n",
    "        layout = {'barmode': 'stack',\n",
    "                  'title': title,\n",
    "                  'xaxis': {'title': 'Quarter', 'ticks': 'outside', 'tickmode': 'array', \n",
    "                            'tickvals': list(range(len(df['quarter']))), \n",
    "                            'ticktext': xlabels_format(df), 'ticklen': 8},\n",
    "                  'yaxis': {'ticks': 'outside', 'title': y_axis_label},\n",
    "                  'showlegend': True,\n",
    "                  'legend': {'orientation': 'h', 'itemclick': 'toggleothers', \n",
    "                             'itemdoubleclick': 'toggle', 'xanchor': 'center', \n",
    "                             'x': 0.5, 'y': -0.11},\n",
    "                  'colorway': COLORS,\n",
    "                  'height': 900}\n",
    "        \n",
    "        fig = go.Figure(data=data, layout={'barmode': 'stack',\n",
    "                                           'title': title,\n",
    "                                           'xaxis': {'title': 'Quarter', 'ticks': 'outside', \n",
    "                                                     'tickmode': 'array', \n",
    "                                                     'tickvals': list(range(len(df['quarter']))), \n",
    "                                                     'ticktext': xlabels_format(df), \n",
    "                                                     'ticklen': 8},\n",
    "                                           'yaxis': {'ticks': 'outside', 'title': y_axis_label},\n",
    "                                           'showlegend': True,\n",
    "                                           'legend': {'font': {'size': fontsize}, \n",
    "                                                      'orientation': 'h', \n",
    "                                                      'itemclick': 'toggleothers', \n",
    "                                                      'itemdoubleclick': 'toggle', \n",
    "                                                      'xanchor': 'center', 'x': 0.5, 'y': -0.11},\n",
    "                                           'colorway': COLORS,\n",
    "                                           'height': 900})\n",
    "        fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    config = {'displayModeBar': True,\n",
    "              'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_bar_chart_settings(df, title, path):\n",
    "    \n",
    "    data = [{ 'type': 'bar',\n",
    "             'name': f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q fact',\n",
    "              'x': df['ticker'].tolist(), \n",
    "              'y': df[f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q fact'].tolist()\n",
    "            },\n",
    "            { 'type': 'bar',\n",
    "             'name': f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q forecast',\n",
    "              'x': df['ticker'].tolist(), \n",
    "              'y': df[f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q forecast'].tolist()\n",
    "            }\n",
    "           ]\n",
    "\n",
    "    layout = { 'barmode': 'group',           \n",
    "               'title': title,\n",
    "               'xaxis': {'ticks': 'outside'},\n",
    "               'yaxis': {'title': 'New Wells Brought Online', 'ticks': 'outside'},\n",
    "               'legend': {'orientation': 'h', 'itemclick': 'toggleothers', \n",
    "                          'itemdoubleclick': 'toggle', \n",
    "                          'xanchor': 'center', 'x': 0.5, 'y': -0.10},\n",
    "               'colorway': COLORS,\n",
    "               'height': 700}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    if '/' in title:\n",
    "        title = title.replace('/', 'and')\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_bar_chart_settings(df, title, type_chart, path):\n",
    "    \n",
    "    if type_chart == 'lateral':\n",
    "        x_axis_label = 'Lateral length, ft'\n",
    "        column = 'value'\n",
    "    elif type_chart == 'distance':\n",
    "        x_axis_label = 'Feet between wells, ft'\n",
    "        column = 'value'\n",
    "    elif type_chart == 'efficiency':\n",
    "        x_axis_label = 'Net Production (Mboe/d)'\n",
    "        column = 'Net Production (Mboe/d)'\n",
    "    \n",
    "    data = [{ 'type': 'bar',\n",
    "              'x': df[column].tolist(),\n",
    "              'y': df['asset_name'].tolist(),          \n",
    "              'orientation': 'h'\n",
    "           }]\n",
    "    \n",
    "\n",
    "    layout = {\n",
    "               'title': title,\n",
    "               'xaxis': {'title': x_axis_label, 'tickformat': '.0'},\n",
    "               'yaxis': {'autorange': 'reversed', 'ticks': 'outside'},\n",
    "               'height': 900, 'width': 900,\n",
    "               'colorway': COLORS,\n",
    "               'margin': {'l': 250}\n",
    "             }\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {str(layout)};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_chart_settings(df, title, type_hc, path):\n",
    "    \n",
    "    if df.empty: # check if values are absent, do not need to display the chart\n",
    "        return ('data : none')\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for asset in df.columns[1:].tolist():\n",
    "        if df[asset].isnull().all():\n",
    "            continue\n",
    "        else:\n",
    "            data.append({ 'type': 'scatter',\n",
    "                     'name': asset,\n",
    "                      'x': list(range(len(df['quarter']))), \n",
    "                      'y': df[asset].tolist(),\n",
    "                      'mode': 'lines+markers',\n",
    "                      'hoverinfo': 'name+y'\n",
    "                    })\n",
    "\n",
    "    if type_hc == 'oil':\n",
    "        y_axis_label = 'bbl/d'\n",
    "    elif type_hc == 'gas':\n",
    "        y_axis_label = 'Mcf/d'\n",
    "        \n",
    "    layout = {            \n",
    "               'title': title,\n",
    "               'xaxis': {'showline': True, 'title': 'Quarter', 'ticks': 'outside', \n",
    "                         'tickmode': 'array', 'tickvals': list(range(len(df['quarter']))), \n",
    "                         'ticktext': xlabels_format(df), 'ticklen': 8},\n",
    "               'yaxis': {'ticks': 'outside', 'title': {'text': y_axis_label, 'standoff': 10}, \n",
    "                         'tickformat': '.0', 'rangemode': 'tozero'},\n",
    "               'showlegend': True,\n",
    "               'legend': {'orientation': 'h', 'itemclick': 'toggleothers', \n",
    "                          'itemdoubleclick': 'toggle', 'xanchor': 'center', 'x': 0.5, 'y': -0.13},\n",
    "               'colorway': COLORS,\n",
    "               'height': 700, 'width': 950}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    layout = str(layout).replace('True', 'true')\n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {layout};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_grouped_bar_chart_settings(df, title, path):\n",
    "    \n",
    "    data = [{ 'type': 'bar',\n",
    "             'name': 'Lateral length, ft',\n",
    "              'x': df['Lateral length, ft'].tolist(), \n",
    "              'y': df['asset'].tolist(),\n",
    "             'orientation': 'h'\n",
    "            },\n",
    "            { 'type': 'bar',\n",
    "             'name': 'Feet between wells, ft',\n",
    "              'x': df['Feet between wells, ft'].tolist(), \n",
    "              'y': df['asset'].tolist(),\n",
    "             'orientation': 'h'\n",
    "            }\n",
    "           ]\n",
    "\n",
    "\n",
    "    layout = { 'barmode': 'group',           \n",
    "               'title': title,\n",
    "               'xaxis': {'tickformat': '.0'},\n",
    "               'yaxis': {'ticks': 'outside', 'ticklen': 8, 'autorange': 'reversed'},\n",
    "               'legend': {'orientation': 'h', 'itemclick': 'toggleothers', \n",
    "                          'itemdoubleclick': 'toggle', 'xanchor': 'center', 'x': 0.5},\n",
    "               'height': 700, 'width': 900,\n",
    "               'colorway': COLORS,\n",
    "               'margin': {'l': 250}}\n",
    "    \n",
    "    config = { 'displayModeBar': True,\n",
    "               'modeBarButtonsToRemove': [ 'sendDataToCloud',\n",
    "                                           'lasso2d',\n",
    "                                           'zoomIn2d',\n",
    "                                           'zoomOut2d',\n",
    "                                           'select2d',\n",
    "                                           'resetScale2d',\n",
    "                                           'toggleSpikelines' ],\n",
    "                'displaylogo': False,\n",
    "                'showTips': True}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    config = str(config).replace('True', 'true').replace('False', 'false')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {str(layout)};\\n'\n",
    "            f'\\nconfig = {config};\\n'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_settings(df, title, path):\n",
    "    \n",
    "    data=[{'type': 'table',\n",
    "           'header': {'values': [df.columns[1]], 'align': 'center', \n",
    "                      'fill': { 'color': 'paleturquoise'}},\n",
    "           'cells': {'values': [df.asset_name.tolist()], 'align': 'center', \n",
    "                     'fill': { 'color': 'lavender'}}}]\n",
    "    \n",
    "    layout = {'title': title, 'height': 700}\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.write_image(f'{path}/pdf/{title}.pdf')\n",
    "    \n",
    "    return (\n",
    "            f'data = {str(data)};\\n'\n",
    "            f'\\nlayout = {str(layout)};\\n'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_code_pie(file_name):\n",
    "    return (\n",
    "f'''\n",
    "    <html>\n",
    "    <head>\n",
    "      <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "    <script src=\"https://s3.amazonaws.com/discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/js/{file_name}.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "      <div id='{file_name}'></div>\n",
    "    </body>\n",
    "        <script language=\"JavaScript\">\n",
    "            Plotly.plot('{file_name}', {{ data:data, layout:layout }});\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_code(file_name):\n",
    "    return (\n",
    "f'''\n",
    "    <html>\n",
    "    <head>\n",
    "    <script src=\"https://s3.amazonaws.com/discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/js/{file_name}.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "      <div id='{file_name}'></div>\n",
    "    </body>\n",
    "        <script language=\"JavaScript\">\n",
    "            Plotly.plot('{file_name}', {{ data:data, layout:layout, config:config }});\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_code_company(company, file_name):\n",
    "    return (\n",
    "f'''\n",
    "    <html>\n",
    "    <head>\n",
    "    <script src=\"https://s3.amazonaws.com/discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/{company}/js/{file_name}.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "      <div id='{file_name}'></div>\n",
    "    </body>\n",
    "        <script language=\"JavaScript\">\n",
    "            Plotly.plot('{file_name}', {{ data:data, layout:layout, config:config }});\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_s3(type_plot, file_name, df, column, title_plot, data=''):\n",
    "    fs = s3fs.S3FileSystem(profile_name='dmitry.zorikhin@XXX')\n",
    "    \n",
    "    local_path = f'../reports/{REPORT_PERIOD}/{BASIN_NAME}/'\n",
    "    js_path = f's3://discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/js/{file_name}.js'\n",
    "    with fs.open(js_path, 'wb') as f:\n",
    "        if type_plot == 'pie':\n",
    "            f.write(get_pie_plot_settings(\n",
    "                df, column, title_plot, local_path).encode())\n",
    "        elif type_plot == 'simple_bar':\n",
    "            f.write(get_simple_bar_chart_settings(\n",
    "                df, column, title_plot, local_path).encode())\n",
    "        elif type_plot == 'bubble':\n",
    "            f.write(get_bubble_chart_settings(df, title_plot, local_path).encode())\n",
    "        elif type_plot == 'horizontal_stack_bar':\n",
    "            f.write(get_horizontal_stack_bar_chart_settings(df, title_plot, local_path).encode())\n",
    "        elif type_plot == 'stacked':\n",
    "            function_return = get_stacked_chart_settings(df, title_plot, data, \n",
    "                                                         local_path, column)\n",
    "            f.write(function_return.encode())\n",
    "        elif type_plot == 'stacked_bar':\n",
    "            function_return = get_stacked_bar_chart_settings(df, title_plot, data, \n",
    "                                                             local_path, column)\n",
    "            f.write(function_return.encode())\n",
    "        elif type_plot == 'grouped_bar':\n",
    "            f.write(get_grouped_bar_chart_settings(df, title_plot, local_path).encode())\n",
    "        elif type_plot == 'horizontal_bar':\n",
    "            f.write(get_horizontal_bar_chart_settings(df, title_plot, data, local_path).encode())\n",
    "        elif type_plot == 'table':\n",
    "            f.write(get_table_settings(df, title_plot, local_path).encode())\n",
    "    fs.chmod(js_path, 'public-read')\n",
    "    \n",
    "    html_path = f's3://discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/html/{file_name}.html'\n",
    "    with fs.open(html_path, 'wb') as f:\n",
    "        if type_plot == 'pie':\n",
    "            f.write(html_code_pie(file_name).encode())\n",
    "        elif (type_plot == 'stacked' and function_return == 'data : none')\\\n",
    "          or (type_plot == 'stacked_bar' and function_return == 'data : none'):\n",
    "            pass\n",
    "        else:\n",
    "            f.write(html_code(file_name).encode())\n",
    "    fs.chmod(html_path, 'public-read')\n",
    "    \n",
    "    with open(f'{local_path}HTML_links_{PERMIAN_TYPE}{TODAY}.html', 'a') as html_file:\n",
    "        if type_plot == 'pie':\n",
    "            html_file.write(html_code_pie(file_name))\n",
    "        elif (type_plot == 'stacked' and function_return == 'data : none')\\\n",
    "          or (type_plot == 'stacked_bar' and function_return == 'data : none'):\n",
    "            pass\n",
    "        else:\n",
    "            html_file.write(html_code(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_company_to_s3(company, type_plot, file_name, df, column, title_plot, data=''):    \n",
    "    \n",
    "    # Creating folders block\n",
    "    local_path = f'../reports/{REPORT_PERIOD}/{BASIN_NAME}/{company}'\n",
    "    try:\n",
    "        os.mkdir(local_path)\n",
    "        os.mkdir(f'{local_path}/pdf')\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        try:\n",
    "            os.mkdir(f'{local_path}/pdf')        \n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "                \n",
    "    fs = s3fs.S3FileSystem(profile_name='dmitry.zorikhin@XXX')\n",
    "    js_path = f's3://discover.energy-XXX{REPORT_PERIOD}/{BASIN_NAME}/{company}/js/{file_name}.js'\n",
    "    with fs.open(js_path, 'wb') as f:\n",
    "        if type_plot == 'line':\n",
    "            function_return = get_line_chart_settings(df, title_plot, data, local_path)\n",
    "            f.write(function_return.encode())\n",
    "        elif type_plot == 'stacked':\n",
    "            function_return = get_stacked_chart_settings(df, title_plot, data, \n",
    "                                                         local_path, column)\n",
    "            f.write(function_return.encode())\n",
    "        elif type_plot == 'stacked_bar':\n",
    "            function_return = get_stacked_bar_chart_settings(df, title_plot, data, \n",
    "                                                             local_path, column)\n",
    "            f.write(function_return.encode())\n",
    "        elif type_plot == 'horizontal_grouped':\n",
    "            f.write(get_horizontal_grouped_bar_chart_settings(df, title_plot, \n",
    "                                                              local_path).encode())\n",
    "    fs.chmod(js_path, 'public-read')\n",
    "    \n",
    "    html_path = f's3://discover.energy-XXX/{REPORT_PERIOD}/{BASIN_NAME}/{company}/html/{file_name}.html'\n",
    "    with fs.open(html_path, 'wb') as f:\n",
    "        if (type_plot == 'stacked' and function_return == 'data : none')\\\n",
    "          or (type_plot == 'stacked_bar' and function_return == 'data : none'):\n",
    "            pass\n",
    "        else:\n",
    "            f.write(html_code_company(company, file_name).encode())\n",
    "    fs.chmod(html_path, 'public-read')\n",
    "    \n",
    "    # Saving html code to paste on discover\n",
    "    with open(f'../reports/{REPORT_PERIOD}/{BASIN_NAME}/{company}/HTML_links_{TODAY}.html', 'a') as html_file:\n",
    "        if (type_plot == 'stacked' and function_return == 'data : none') \\\n",
    "          or (type_plot == 'stacked_bar' and function_return == 'data : none') \\\n",
    "           or (type_plot == 'line' and function_return == 'data : none'):\n",
    "            pass\n",
    "        else:\n",
    "            html_file.write(html_code_company(company, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlabels_format(df):\n",
    "    raw_labels_list = df['quarter'].astype(str).tolist()\n",
    "    xlabels_list = (['\\'' + raw_labels_list[elem][2:4] + ' Q' \n",
    "                     + raw_labels_list[elem][4] for elem in range(len(raw_labels_list))])\n",
    "    return xlabels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pdf(file_name_list, name, level, company=''):\n",
    "    \n",
    "    if level == 'basin':\n",
    "        os.chdir(f'{path}/{BASIN_NAME}/pdf')\n",
    "    elif level == 'company':\n",
    "        os.chdir(f'{path}/{BASIN_NAME}/{company}/pdf')\n",
    "    pdfWriter = PyPDF2.PdfFileWriter()\n",
    "\n",
    "    for filename in file_name_list:\n",
    "        try:\n",
    "            pdfFileObj = open(filename,'rb')\n",
    "            pdfReader = PyPDF2.PdfFileReader(pdfFileObj, strict=False)\n",
    "            \n",
    "            # Opening each page of the PDF\n",
    "            for pageNum in range(pdfReader.numPages):\n",
    "                pageObj = pdfReader.getPage(pageNum)\n",
    "                pdfWriter.addPage(pageObj)\n",
    "\n",
    "            pdfOutput = open(f'../PLOTS - {name}.pdf', 'wb')    \n",
    "            pdfWriter.write(pdfOutput)    \n",
    "            pdfOutput.close()\n",
    "        \n",
    "        except OSError as e:\n",
    "            if e.errno == errno.ENOENT:\n",
    "                print(f'{filename} does not exist')\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if level == 'basin':\n",
    "        os.chdir('../../../../_scripts')\n",
    "    elif level == 'company':\n",
    "        os.chdir('../../../../../_scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capex and Net Production Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_to_check = tm.time()\n",
    "# This required to merge pdf in the order they appear in report\n",
    "capex_net_production_file_names = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fiscal Year 2019 Capex and Net Production per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_per_company = dataset_for_analysis_basin_level(assets_basins_dataset, 'capex_value', \n",
    "                                                     name_basin=BASIN_NAME, \n",
    "                                                     aggregate_basis='company', \n",
    "                                                     start_quarter=START_QUARTER_ACTUAL, \n",
    "                                                     end_quarter=END_QUARTER_ACTUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_per_company = capex_per_company.droplevel([1, 2]).reset_index()\n",
    "\n",
    "capex_per_company['Capex ($MM)'] = capex_per_company.sum(axis=1)\n",
    "\n",
    "capex_per_company = capex_per_company[['ticker', 'Capex ($MM)']].copy()\n",
    "\n",
    "capex_per_company = (capex_per_company\n",
    "                     .groupby(['ticker'])\n",
    "                     .sum()\n",
    "                     .reset_index()\n",
    "                     .rename(columns={'ticker':'Company'}))\n",
    "capex_per_company = capex_per_company.sort_values(by='Capex ($MM)', ascending=False)\n",
    "\n",
    "companies_in_basin = sorted(list(capex_per_company.Company))\n",
    "companies_in_basin = ', '.join(companies_in_basin)\n",
    "\n",
    "# Metric id for net production\n",
    "net_production = asset_data_df[asset_data_df['asset_metric_id'] == 162].copy() \n",
    "\n",
    "company_basin = (assets_basins_dataset[assets_basins_dataset['name_basin'] == BASIN_NAME]\n",
    "                 [['asset_id', 'ticker']].drop_duplicates().copy())\n",
    "\n",
    "company_net_production = (net_production\n",
    "                          .merge(company_basin, left_on=['asset_id'], \n",
    "                                 right_on=['asset_id'], how='inner')[['ticker', 'value']])\n",
    "\n",
    "company_net_production['value'] = company_net_production['value'].astype(float)\n",
    "company_net_production = (company_net_production\n",
    "                          .groupby(['ticker'])\n",
    "                          .sum()\n",
    "                          .reset_index()\n",
    "                          .rename(columns={'ticker':'Company', \n",
    "                                           'value':'Net Production (Mboe/d)'}))\n",
    "\n",
    "capex_net_production = capex_per_company.merge(company_net_production, left_on='Company', \n",
    "                                               right_on='Company', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('pie', f'Actual_{BASIN_NAME}_Capex_{PERMIAN_TYPE}{TODAY}', \n",
    "             capex_net_production, 'Capex ($MM)', \n",
    "             f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex ($MM)')\n",
    "(capex_net_production_file_names\n",
    " .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex ($MM).pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Net Production per Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('pie', f'Actual_{BASIN_NAME}_Net_Production_{PERMIAN_TYPE}{TODAY}', \n",
    "             capex_net_production, 'Net Production (Mboe/d)',\n",
    "             f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Net Production (Mboe/d)')\n",
    "(capex_net_production_file_names\n",
    " .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Net Production (Mboe per d).pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric id for capex\n",
    "fy_capex_from_metrics = asset_data_df[asset_data_df['asset_metric_id'] == 165].copy()\n",
    "\n",
    "company_fy_capex_from_metrics = (fy_capex_from_metrics\n",
    "                                 .merge(company_basin, left_on=['asset_id'], \n",
    "                                        right_on=['asset_id'], how='inner')[['ticker', 'value']])\n",
    "\n",
    "company_fy_capex_from_metrics['value'] = company_fy_capex_from_metrics['value'].astype(float)\n",
    "company_fy_capex_from_metrics = (company_fy_capex_from_metrics\n",
    "                                 .groupby(['ticker'])\n",
    "                                 .sum()\n",
    "                                 .reset_index()\n",
    "                                 .rename(columns={'ticker':'Company', \n",
    "                                                  'value':'Capex_metrics ($MM)'}))\n",
    "\n",
    "capex_check = (company_fy_capex_from_metrics\n",
    "               .merge(capex_per_company, left_on=['Company'], \n",
    "                      right_on=['Company'], how='inner'))\n",
    "capex_check['difference'] = (round(capex_check['Capex_metrics ($MM)'] \n",
    "                                   - capex_check['Capex ($MM)'], 1))\n",
    "capex_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020 Forecasted Capex per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_per_company_forecasted = dataset_for_analysis_basin_level(assets_basins_dataset, \n",
    "                                                                'capex_value', \n",
    "                                                                name_basin=BASIN_NAME, \n",
    "                                                                aggregate_basis='company', \n",
    "                                                                start_quarter=START_QUARTER_FORECAST, \n",
    "                                                                end_quarter=END_QUARTER_FORECAST)\n",
    "\n",
    "capex_per_company_forecasted = capex_per_company_forecasted.droplevel([1, 2]).reset_index()\n",
    "\n",
    "capex_per_company_forecasted['Capex ($MM)'] = capex_per_company_forecasted.sum(axis=1)\n",
    "\n",
    "capex_per_company_forecasted = capex_per_company_forecasted[['ticker', 'Capex ($MM)']].copy()\n",
    "\n",
    "capex_per_company_forecasted = (capex_per_company_forecasted\n",
    "                                .groupby(['ticker'])\n",
    "                                .sum()\n",
    "                                .reset_index()\n",
    "                                .rename(columns={'ticker':'Company'}))\n",
    "capex_per_company_forecasted = (capex_per_company_forecasted\n",
    "                                .sort_values(by='Capex ($MM)', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('pie', f'Forecasted_{BASIN_NAME}_Capex_{PERMIAN_TYPE}{TODAY}', \n",
    "             capex_per_company_forecasted, 'Capex ($MM)',\n",
    "             f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex ($MM)')\n",
    "(capex_net_production_file_names\n",
    " .append(f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex ($MM).pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fiscal Year 2019 Capex per asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_per_asset = dataset_for_analysis_basin_level(assets_basins_dataset, 'capex_value', \n",
    "                                                   name_basin=BASIN_NAME, aggregate_basis='basin', \n",
    "                                                   start_quarter=START_QUARTER_ACTUAL, \n",
    "                                                   end_quarter=END_QUARTER_ACTUAL)\n",
    "\n",
    "capex_per_asset = capex_per_asset.droplevel([0]).reset_index()\n",
    "\n",
    "capex_per_asset['Capex ($MM)'] = capex_per_asset.sum(axis=1)\n",
    "\n",
    "capex_per_asset['asset_name'] = '('+capex_per_asset['ticker']+') '+capex_per_asset['name']\n",
    "\n",
    "capex_per_asset_plot = capex_per_asset[['ticker', 'name', 'asset_name', 'Capex ($MM)']].copy()\n",
    "capex_per_asset = capex_per_asset[['asset_name', 'Capex ($MM)']].copy()\n",
    "\n",
    "capex_per_asset = capex_per_asset.sort_values(by='Capex ($MM)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASIN_NAME == 'Permian' and assets_count > 30:\n",
    "    # This number of assets will be displayed on separate graphs and depends on total assets \n",
    "    # (max on single graph is 35 otherwise xlabels broken)\n",
    "    n = 20 \n",
    "    non_zero_capex_assets_number = capex_per_asset[capex_per_asset['Capex ($MM)'] != 0].shape[0]\n",
    "    actual_capex_per_asset_first_part = (capex_per_asset[capex_per_asset['Capex ($MM)'] != 0]\n",
    "                                         .iloc[:n])\n",
    "    actual_capex_per_asset_second_part = (capex_per_asset[capex_per_asset['Capex ($MM)'] != 0]\n",
    "                                          .iloc[n:])\n",
    "    zero_capex_per_asset = capex_per_asset[capex_per_asset['Capex ($MM)'] == 0]\n",
    "    \n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Actual_Capex_Allocation_by_Asset_(1st-{n-1}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_first_part, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation (1st-{n-1}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation (1st-{n-1}th assets).pdf'))\n",
    "    \n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Actual_Capex_Allocation_by_Asset_({n}th-{non_zero_capex_assets_number}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_second_part, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation ({n}th-{non_zero_capex_assets_number}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation ({n}th-{non_zero_capex_assets_number}th assets).pdf'))\n",
    "    \n",
    "    if not zero_capex_per_asset.empty:\n",
    "        export_to_s3('table', \n",
    "                     f'{BASIN_NAME}_Actual_Capex_Allocation_by_Asset_(zero_capex_table)_{PERMIAN_TYPE}{TODAY}', \n",
    "                     zero_capex_per_asset, '', \n",
    "                     f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation (no capex allocated)')\n",
    "        (capex_net_production_file_names\n",
    "         .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation (no capex allocated).pdf'))\n",
    "\n",
    "else:\n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Actual_Capex_Allocation_by_Asset_{PERMIAN_TYPE}{TODAY}', \n",
    "                 capex_per_asset, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation by Asset')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Actual Capex Allocation by Asset.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020 Forecasted Capex per asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_per_asset_forecasted = dataset_for_analysis_basin_level(assets_basins_dataset, \n",
    "                                                              'capex_value', \n",
    "                                                              name_basin=BASIN_NAME, \n",
    "                                                              aggregate_basis='basin', \n",
    "                                                              start_quarter=START_QUARTER_FORECAST, \n",
    "                                                              end_quarter=END_QUARTER_FORECAST)\n",
    "\n",
    "capex_per_asset_forecasted = capex_per_asset_forecasted.droplevel([0]).reset_index()\n",
    "\n",
    "capex_per_asset_forecasted['Capex ($MM)'] = capex_per_asset_forecasted.sum(axis=1)\n",
    "\n",
    "capex_per_asset_forecasted['asset_name'] = ('(' + capex_per_asset_forecasted['ticker']\n",
    "                                            + ') ' + capex_per_asset_forecasted['name'])\n",
    "\n",
    "capex_per_asset_forecasted = capex_per_asset_forecasted[['asset_name', 'Capex ($MM)']].copy()\n",
    "capex_per_asset_forecasted = capex_per_asset_forecasted.sort_values(by='Capex ($MM)', \n",
    "                                                                    ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASIN_NAME == 'Permian' and assets_count > 30:\n",
    "    # This number of assets will be displayed on separate graphs and depends on total assets \n",
    "    # (max on single graph is 35 otherwise xlabels broken)\n",
    "    n = 20 \n",
    "    non_zero_capex_assets_number_forecasted = (capex_per_asset_forecasted[\n",
    "        capex_per_asset_forecasted['Capex ($MM)'] != 0].shape[0])\n",
    "    actual_capex_per_asset_first_part_forecasted = (capex_per_asset_forecasted[\n",
    "        capex_per_asset_forecasted['Capex ($MM)'] != 0].iloc[:n])\n",
    "    actual_capex_per_asset_second_part_forecasted = (capex_per_asset_forecasted[\n",
    "        capex_per_asset_forecasted['Capex ($MM)'] != 0].iloc[n:])\n",
    "    zero_capex_per_asset_forecasted = (capex_per_asset_forecasted[\n",
    "        capex_per_asset_forecasted['Capex ($MM)'] == 0])\n",
    "    \n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Forecasted_Capex_Allocation_by_Asset_(1st-{n-1}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_first_part_forecasted, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation (1st-{n-1}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation (1st-{n-1}th assets).pdf'))\n",
    "    \n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Forecasted_Capex_Allocation_by_Asset_({n}th-{non_zero_capex_assets_number}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_second_part_forecasted, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation ({n}th-{non_zero_capex_assets_number_forecasted}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation ({n}th-{non_zero_capex_assets_number_forecasted}th assets).pdf'))\n",
    "    \n",
    "    if not zero_capex_per_asset_forecasted.empty:\n",
    "        export_to_s3('table', \n",
    "                     f'{BASIN_NAME}_Forecasted_Capex_Allocation_by_Asset_(zero_capex_table)_{TODAY}', \n",
    "                     zero_capex_per_asset_forecasted, '', \n",
    "                     f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation (no capex allocated)')\n",
    "        (capex_net_production_file_names\n",
    "         .append(f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation (no capex allocated).pdf'))\n",
    "\n",
    "else:\n",
    "    export_to_s3('simple_bar', \n",
    "                 f'{BASIN_NAME}_Forecasted_Capex_Allocation_by_Asset_{PERMIAN_TYPE}{TODAY}', \n",
    "                 capex_per_asset_forecasted, 'Capex ($MM)',\n",
    "                 f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation by Asset')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q {BASIN_NAME} Forecasted Capex Allocation by Asset.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019 Capex Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_production = asset_data_df[asset_data_df['asset_metric_id'] == 162].copy()\n",
    "\n",
    "assets_basin = (assets_basins_dataset[assets_basins_dataset['name_basin'] == BASIN_NAME]\n",
    "                [['asset_id', 'ticker', 'name']].drop_duplicates().copy())\n",
    "\n",
    "assets_basin['asset_name'] = '('+assets_basin['ticker']+') '+assets_basin['name']\n",
    "\n",
    "assets_net_production = (net_production.merge(assets_basin, left_on=['asset_id'], \n",
    "                                              right_on=['asset_id'], how='inner')\n",
    "                         [['asset_name', 'value']])\n",
    "assets_net_production_plot = (net_production.merge(assets_basin, left_on=['asset_id'], \n",
    "                                                   right_on=['asset_id'], how='inner')\n",
    "                              [['ticker', 'name', 'asset_name', 'value']])\n",
    "\n",
    "assets_net_production['value'] = assets_net_production['value'].astype(float)\n",
    "assets_net_production_plot['value'] = assets_net_production_plot['value'].astype(float)\n",
    "assets_net_production = assets_net_production.sort_values(by='value', ascending=False)\n",
    "\n",
    "capex_efficiency = (capex_per_asset\n",
    "                    .merge(assets_net_production, left_on=['asset_name'], \n",
    "                           right_on=['asset_name'], how='inner')\n",
    "                    .rename(columns={'sum':'Net Capex ($MM)', \n",
    "                                     'value':'Net Production (Mboe/d)'}))\n",
    "capex_efficiency_plot = (capex_per_asset_plot\n",
    "                         .merge(assets_net_production_plot, left_on=['asset_name'], \n",
    "                                right_on=['asset_name'], how='inner', suffixes=('', '_y'))\n",
    "                         .rename(columns={'sum':'Net Capex ($MM)', \n",
    "                                          'value':'Net Production (Mboe/d)'})\n",
    "                         [['ticker', 'name', 'asset_name', \n",
    "                           'Capex ($MM)', 'Net Production (Mboe/d)']])\n",
    "capex_efficiency_plot = capex_efficiency_plot.round({'Capex ($MM)': 1, \n",
    "                                                     'Net Production (Mboe/d)': 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASIN_NAME == 'Permian' and assets_count > 30:\n",
    "    capex_efficiency_plot = (capex_efficiency_plot\n",
    "                             .sort_values(by='Capex ($MM)', ascending=False)\n",
    "                             .dropna())\n",
    "    # This number of assets will be displayed on separate graphs and depends on total assets \n",
    "    # (max on single graph is 35 otherwise xlabels broken)\n",
    "    n = 20\n",
    "    non_zero_capex_assets_number_efficiency = (capex_efficiency_plot[\n",
    "        capex_efficiency_plot['Capex ($MM)'] != 0].shape[0])\n",
    "    actual_capex_per_asset_first_part_efficiency = (capex_efficiency_plot[\n",
    "        capex_efficiency_plot['Capex ($MM)'] != 0].iloc[:n])\n",
    "    actual_capex_per_asset_second_part_efficiency = (capex_efficiency_plot[\n",
    "        capex_efficiency_plot['Capex ($MM)'] != 0].iloc[n:])\n",
    "    zero_capex_per_asset_efficiency = (capex_efficiency_plot[\n",
    "        capex_efficiency_plot['Capex ($MM)'] == 0])\n",
    "    zero_capex_per_asset_efficiency = (zero_capex_per_asset_efficiency\n",
    "                                       .sort_values(by='Net Production (Mboe/d)', \n",
    "                                                    ascending=False))\n",
    "    \n",
    "    export_to_s3('bubble', \n",
    "                 f'{BASIN_NAME}_Capex_Efficiency_(1st-{n-1}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_first_part_efficiency, '',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency (1st-{n-1}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency (1st-{n-1}th assets).pdf'))\n",
    "    \n",
    "    export_to_s3('bubble', \n",
    "                 f'{BASIN_NAME}_Capex_Efficiency_({n}th-{non_zero_capex_assets_number}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 actual_capex_per_asset_second_part_efficiency, '',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency ({n}th-{non_zero_capex_assets_number_efficiency}th assets)')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency ({n}th-{non_zero_capex_assets_number_efficiency}th assets).pdf'))    \n",
    "    \n",
    "    if not zero_capex_per_asset_efficiency.empty:\n",
    "        export_to_s3('horizontal_bar', \n",
    "                     f'{BASIN_NAME}_Capex_Efficiency_(zero_capex_table)_{PERMIAN_TYPE}{TODAY}', \n",
    "                     zero_capex_per_asset_efficiency, '', \n",
    "                     f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency (no capex allocated)', 'efficiency')\n",
    "        (capex_net_production_file_names\n",
    "         .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency (no capex allocated).pdf'))\n",
    "\n",
    "else:\n",
    "    export_to_s3('bubble', \n",
    "                 f'{BASIN_NAME}_Capex_Efficiency_{PERMIAN_TYPE}{TODAY}', \n",
    "                 capex_efficiency_plot, '',\n",
    "                 f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency')\n",
    "    (capex_net_production_file_names\n",
    "     .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Efficiency.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019 Capex proportion per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_capex_proportion_per_company = dataset_for_analysis_basin_level(assets_basins_dataset, \n",
    "                                                                      'capex_value', \n",
    "                                                                      name_basin='', \n",
    "                                                                      aggregate_basis='company', \n",
    "                                                                      start_quarter=START_QUARTER_ACTUAL, \n",
    "                                                                      end_quarter=END_QUARTER_ACTUAL)\n",
    "\n",
    "total_capex_proportion_per_company = (total_capex_proportion_per_company\n",
    "                                      .droplevel([1, 2]).reset_index())\n",
    "\n",
    "total_capex_proportion_per_company['sum'] = total_capex_proportion_per_company.sum(axis=1)\n",
    "\n",
    "total_capex_proportion_per_company = (total_capex_proportion_per_company[['ticker', 'sum']]\n",
    "                                      .copy())\n",
    "\n",
    "total_capex_proportion_per_company = (total_capex_proportion_per_company\n",
    "                                      .groupby(['ticker']).sum().reset_index())\n",
    "total_capex_proportion_per_company = (total_capex_proportion_per_company\n",
    "                                      .sort_values(by='sum', ascending=False))\n",
    "\n",
    "capex_proportion_per_company = (capex_per_company\n",
    "                                .merge(total_capex_proportion_per_company, left_on=['Company'], \n",
    "                                       right_on=['ticker'], how='left')\n",
    "                                .rename(columns={'Capex ($MM)': BASIN_NAME, \n",
    "                                                 'sum':'total_capex'}))\n",
    "\n",
    "capex_proportion_per_company['Other basins'] = (capex_proportion_per_company['total_capex'] \n",
    "                                                - capex_proportion_per_company[BASIN_NAME])\n",
    "\n",
    "capex_proportion_per_company_plot = capex_proportion_per_company.copy()\n",
    "(capex_proportion_per_company_plot\n",
    " [f'{BASIN_NAME}_p']) = (round((capex_proportion_per_company_plot[BASIN_NAME] \n",
    "                                / capex_proportion_per_company_plot['total_capex']), 2))\n",
    "(capex_proportion_per_company_plot\n",
    " ['Other_basins_p']) = (round((capex_proportion_per_company_plot['Other basins'] \n",
    "                               / capex_proportion_per_company_plot['total_capex']), 2))\n",
    "\n",
    "capex_proportion_per_company = capex_proportion_per_company.drop(['total_capex', 'ticker'], \n",
    "                                                                 axis=1)\n",
    "capex_proportion_per_company_plot = capex_proportion_per_company_plot.drop(['total_capex', \n",
    "                                                                            'ticker'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('horizontal_stack_bar', \n",
    "             f'{BASIN_NAME}_Capex_Proportion_per_Company_{PERMIAN_TYPE}{TODAY}', \n",
    "             capex_proportion_per_company_plot, '',\n",
    "             f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Proportion per Company')\n",
    "(capex_net_production_file_names\n",
    " .append(f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q {BASIN_NAME} Capex Proportion per Company.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capex_net_production_filename = f'{BASIN_NAME} Capex and Net Production ({companies_in_basin}) {TODAY}'\n",
    "\n",
    "with pd.ExcelWriter(f'{path}/{BASIN_NAME}/DATA - {capex_net_production_filename}.xlsx', \n",
    "                    engine = 'xlsxwriter') as writer:\n",
    "    \n",
    "    capex_net_production.to_excel(writer, index=False, \n",
    "                                  sheet_name='Actual Capex and Net Production')\n",
    "    worksheet = writer.sheets['Actual Capex and Net Production']\n",
    "    worksheet.set_column('A:D', 20)\n",
    "    \n",
    "    capex_per_company_forecasted.to_excel(writer, index=False, \n",
    "                                          sheet_name = 'Forecasted Capex')\n",
    "    worksheet = writer.sheets['Forecasted Capex']\n",
    "    worksheet.set_column('A:D', 20)\n",
    "    \n",
    "    capex_per_asset.to_excel(writer, index=False, \n",
    "                             sheet_name = 'Actual Capex per asset')\n",
    "    worksheet = writer.sheets['Actual Capex per asset']\n",
    "    worksheet.set_column('A:D', 25)\n",
    "    \n",
    "    capex_per_asset_forecasted.to_excel(writer, index=False, \n",
    "                                        sheet_name = 'Forecasted Capex per asset')\n",
    "    worksheet = writer.sheets['Forecasted Capex per asset']\n",
    "    worksheet.set_column('A:D', 25)\n",
    "    \n",
    "    capex_efficiency.to_excel(writer, index=False, \n",
    "                              sheet_name = 'Actual Capex Efficiency')\n",
    "    worksheet = writer.sheets['Actual Capex Efficiency']\n",
    "    worksheet.set_column('A:D', 25)\n",
    "    \n",
    "    capex_proportion_per_company.to_excel(writer, index=False, \n",
    "                                          sheet_name = 'Actual Capex Proportion')\n",
    "    worksheet = writer.sheets['Actual Capex Proportion']\n",
    "    worksheet.set_column('A:D', 20)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    merge_pdf(capex_net_production_file_names, capex_net_production_filename, 'basin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production, rig and well count per asset section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_rig_well_count_file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(initial_dataset, parameter, name_basin, start_quarter, end_quarter):\n",
    "    \n",
    "    \"\"\"Initial_dataset is assets_basins_dataset - as default\n",
    "    parameter - either oil_value, gas_value, rig_count_value, well_count_value\n",
    "    \"\"\"\n",
    "    \n",
    "    production = dataset_for_analysis_basin_level(initial_dataset, parameter, \n",
    "                                                  name_basin=name_basin, \n",
    "                                                  aggregate_basis='company', \n",
    "                                                  start_quarter=start_quarter, \n",
    "                                                  end_quarter=end_quarter)\n",
    "    production = production.droplevel([1]).reset_index()\n",
    "    production['asset_name'] = '('+production['ticker']+') '+production['name']\n",
    "    production = production.drop(['ticker', 'name'], axis=1)\n",
    "    production = production.set_index('asset_name')\n",
    "    production_transposed = production.T.reset_index()\n",
    "    \n",
    "    return production_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_production_basin = production(assets_basins_dataset, 'oil_value', BASIN_NAME, \n",
    "                                  START_QUARTER_ACTUAL, END_QUARTER_FORECAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('stacked', f'{BASIN_NAME}_Oil_Production_{PERMIAN_TYPE}{TODAY}', \n",
    "             oil_production_basin, 'general', f'{BASIN_NAME} Oil Production', 'oil')\n",
    "production_rig_well_count_file_names.append(f'{BASIN_NAME} Oil Production.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_production_basin = production(assets_basins_dataset, 'gas_value', BASIN_NAME, \n",
    "                                  START_QUARTER_ACTUAL, END_QUARTER_FORECAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('stacked', f'{BASIN_NAME}_Gas_Production_{PERMIAN_TYPE}{TODAY}', \n",
    "             gas_production_basin, 'general', f'{BASIN_NAME} Gas Production', 'gas')\n",
    "production_rig_well_count_file_names.append(f'{BASIN_NAME} Gas Production.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_count_value_basin = production(assets_basins_dataset, 'rig_count_value', BASIN_NAME, \n",
    "                                   START_QUARTER_ACTUAL, END_QUARTER_FORECAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('stacked_bar', f'{BASIN_NAME}_Active_Rigs_{PERMIAN_TYPE}{TODAY}', \n",
    "             rig_count_value_basin, 'general', f'{BASIN_NAME} Active Rigs', 'rig')\n",
    "production_rig_well_count_file_names.append(f'{BASIN_NAME} Active Rigs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_count_value_per_quarter = production(assets_basins_dataset, 'well_count_value', \n",
    "                                          BASIN_NAME, START_QUARTER_ACTUAL, \n",
    "                                          END_QUARTER_FORECAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('stacked_bar', \n",
    "             f'{BASIN_NAME}_New_Wells_Brought_Online_Quarterly_{PERMIAN_TYPE}{TODAY}', \n",
    "             well_count_value_per_quarter, 'general', \n",
    "             f'{BASIN_NAME} New Wells Brought Online Quarterly', 'well')\n",
    "(production_rig_well_count_file_names\n",
    " .append(f'{BASIN_NAME} New Wells Brought Online Quarterly.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fact / Forecast Basin New Wells Brought Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wells_fact = dataset_for_analysis_basin_level(assets_basins_dataset, 'well_count_value', \n",
    "                                                  name_basin=BASIN_NAME, aggregate_basis='basin', \n",
    "                                                  start_quarter=START_QUARTER_ACTUAL, \n",
    "                                                  end_quarter=END_QUARTER_ACTUAL)\n",
    "\n",
    "new_wells_fact = new_wells_fact.droplevel([0, 2]).reset_index()\n",
    "new_wells_fact = new_wells_fact.groupby('ticker').sum().reset_index()\n",
    "new_wells_fact_period_name = f'{START_QUARTER_ACTUAL}Q-{END_QUARTER_ACTUAL}Q fact'\n",
    "new_wells_fact[new_wells_fact_period_name] = new_wells_fact.sum(axis=1)\n",
    "new_wells_fact = new_wells_fact[['ticker', new_wells_fact_period_name]].copy()\n",
    "new_wells_fact = new_wells_fact.sort_values(by=new_wells_fact_period_name, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wells_forecast = dataset_for_analysis_basin_level(assets_basins_dataset, 'well_count_value', \n",
    "                                                      name_basin=BASIN_NAME, \n",
    "                                                      aggregate_basis='basin', \n",
    "                                                      start_quarter=START_QUARTER_FORECAST, \n",
    "                                                      end_quarter=END_QUARTER_FORECAST)\n",
    "\n",
    "new_wells_forecast = new_wells_forecast.droplevel([0, 2]).reset_index()\n",
    "new_wells_forecast = new_wells_forecast.groupby('ticker').sum().reset_index()\n",
    "new_wells_forecast_period_name = f'{START_QUARTER_FORECAST}Q-{END_QUARTER_FORECAST}Q forecast'\n",
    "new_wells_forecast[new_wells_forecast_period_name] = new_wells_forecast.sum(axis=1)\n",
    "new_wells_forecast = new_wells_forecast[['ticker', new_wells_forecast_period_name]].copy()\n",
    "new_wells_forecast = (new_wells_forecast\n",
    "                      .sort_values(by=new_wells_forecast_period_name, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wells_plan_forecast = new_wells_fact.merge(new_wells_forecast, left_on='ticker', \n",
    "                                               right_on='ticker', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_s3('grouped_bar', \n",
    "             f'Fact_Forecast_{BASIN_NAME}_New_Wells_Brought_Online_{PERMIAN_TYPE}{TODAY}', \n",
    "             new_wells_plan_forecast, '', f'Fact / Forecast {BASIN_NAME} New Wells Brought Online')\n",
    "(production_rig_well_count_file_names\n",
    " .append(f'Fact and Forecast {BASIN_NAME} New Wells Brought Online.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lateral length / feet between wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateral_length_feet_between_wells(asset_data_dataset, initial_dataset, \n",
    "                                      asset_metric_id, name_basin, parameter):\n",
    "    \n",
    "    \"\"\"\n",
    "    asset_data_dataset should be asset_data_df\n",
    "    initial_dataset is assets_basins_dataset - as default\n",
    "    integer value asset_metric_id either 11 for lateral length or 12 for feet between wells\n",
    "    parameter - 'assets_level' or 'company_level'\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_dataset = asset_data_dataset[asset_data_dataset['asset_metric_id'] == asset_metric_id].copy()\n",
    "    assets_basin = (initial_dataset[initial_dataset['name_basin'] == name_basin]\n",
    "                    [['asset_id', 'ticker', 'name']].drop_duplicates().copy())\n",
    "    assets_basin['asset_name'] = '('+assets_basin['ticker']+') '+assets_basin['name']\n",
    "    \n",
    "    if parameter == 'assets_level':\n",
    "        assets_metric = (metric_dataset.merge(assets_basin, left_on=['asset_id'], \n",
    "                                              right_on=['asset_id'], how='inner')\n",
    "                         [['asset_name', 'value']])\n",
    "    elif parameter == 'company_level':\n",
    "        assets_metric = (metric_dataset\n",
    "                         .merge(assets_basin, left_on=['asset_id'], \n",
    "                                right_on=['asset_id'], how='inner'))\n",
    "    assets_metric['value'] = assets_metric['value'].astype(int)\n",
    "    assets_metric = assets_metric.sort_values(by='value', ascending=False)\n",
    "    \n",
    "    return assets_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_lateral_length = lateral_length_feet_between_wells(asset_data_df, assets_basins_dataset, \n",
    "                                                          11, BASIN_NAME, 'assets_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASIN_NAME == 'Permian' and assets_count > 70:\n",
    "    n = 45 # first n assets to display\n",
    "    assets_number = assets_lateral_length.shape[0]\n",
    "    assets_lateral_length_first_part = assets_lateral_length.iloc[:n]\n",
    "    assets_lateral_length_second_part = assets_lateral_length.iloc[n:]\n",
    "    \n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Asset_Wells_Lateral_Length_(first_{n-1}_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_lateral_length_first_part, '',\n",
    "                 f'{BASIN_NAME} Asset Wells Lateral Length (first {n-1} assets)', 'lateral')\n",
    "    (production_rig_well_count_file_names\n",
    "     .append(f'{BASIN_NAME} Asset Wells Lateral Length (first {n-1} assets).pdf'))\n",
    "    \n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Asset_Wells_Lateral_Length_({n}th-{assets_number}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_lateral_length_second_part, '',\n",
    "                 f'{BASIN_NAME} Asset Wells Lateral Length ({n}th-{assets_number}th assets)', \n",
    "                 'lateral')\n",
    "    (production_rig_well_count_file_names\n",
    "     .append(f'{BASIN_NAME} Asset Wells Lateral Length ({n}th-{assets_number}th assets).pdf'))\n",
    "else:\n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Asset_Wells_Lateral_Length_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_lateral_length, '',\n",
    "                 f'{BASIN_NAME} Asset Wells Lateral Length', 'lateral')\n",
    "    production_rig_well_count_file_names.append(f'{BASIN_NAME} Asset Wells Lateral Length.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_feet_between_wells = lateral_length_feet_between_wells(asset_data_df, \n",
    "                                                              assets_basins_dataset, \n",
    "                                                              12, BASIN_NAME, 'assets_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASIN_NAME == 'Permian' and assets_count > 70:\n",
    "    n = 45 # first n assets to display\n",
    "    assets_number = assets_feet_between_wells.shape[0]\n",
    "    assets_feet_between_wells_first_part = assets_feet_between_wells.iloc[:n]\n",
    "    assets_feet_between_wells_second_part = assets_feet_between_wells.iloc[n:]\n",
    "    \n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Feet_Between_Wells_(first_{n-1}_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_feet_between_wells_first_part, '',\n",
    "                 f'{BASIN_NAME} Feet Between Wells (first {n-1} assets)', 'distance')\n",
    "    production_rig_well_count_file_names.append(f'{BASIN_NAME} Feet Between Wells (first {n-1} assets).pdf')\n",
    "    \n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Feet_Between_Wells_({n}th-{assets_number}th_assets)_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_feet_between_wells_second_part, '',\n",
    "                 f'{BASIN_NAME} Feet Between Wells ({n}th-{assets_number}th assets)', 'distance')\n",
    "    (production_rig_well_count_file_names\n",
    "     .append(f'{BASIN_NAME} Feet Between Wells ({n}th-{assets_number}th assets).pdf'))\n",
    "else:    \n",
    "    export_to_s3('horizontal_bar', \n",
    "                 f'{BASIN_NAME}_Feet_Between_Wells_{PERMIAN_TYPE}{TODAY}', \n",
    "                 assets_feet_between_wells, '',\n",
    "                 f'{BASIN_NAME} Feet Between Wells', 'distance')\n",
    "    production_rig_well_count_file_names.append(f'{BASIN_NAME} Feet Between Wells.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_lateral_length_feet_between_wells = (assets_lateral_length\n",
    "                                            .merge(assets_feet_between_wells, \n",
    "                                                   left_on=['asset_name'], \n",
    "                                                   right_on=['asset_name'], \n",
    "                                                   how='inner')\n",
    "                                            .rename(columns={'value_x':'Lateral length, ft', \n",
    "                                                             'value_y':'Feet between wells, ft'})\n",
    "                                            [['asset_name', 'Lateral length, ft', \n",
    "                                              'Feet between wells, ft']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_rigs_wells_filename = f'{BASIN_NAME} Production, New Wells and Rigs ({companies_in_basin}) {TODAY}'\n",
    "\n",
    "with pd.ExcelWriter(f'{path}/{BASIN_NAME}/DATA - {production_rigs_wells_filename}.xlsx', engine = 'xlsxwriter') as writer:\n",
    "    \n",
    "    oil_production_basin.to_excel(writer, index=False, sheet_name='Oil Production')\n",
    "    worksheet = writer.sheets['Oil Production']\n",
    "    worksheet.set_column('A:BA', 25)\n",
    "    \n",
    "    gas_production_basin.to_excel(writer, index=False, sheet_name = 'Gas Production')\n",
    "    worksheet = writer.sheets['Gas Production']\n",
    "    worksheet.set_column('A:BA', 25)\n",
    "    \n",
    "    rig_count_value_basin.to_excel(writer, index=False, sheet_name = 'Active Rigs')\n",
    "    worksheet = writer.sheets['Active Rigs']\n",
    "    worksheet.set_column('A:BA', 25)\n",
    "    \n",
    "    well_count_value_per_quarter.to_excel(writer, index=False, \n",
    "                                          sheet_name = 'Wells Brought Online Quarter')\n",
    "    worksheet = writer.sheets['Wells Brought Online Quarter']\n",
    "    worksheet.set_column('A:BA', 30)\n",
    "    \n",
    "    new_wells_plan_forecast.to_excel(writer, index=False, \n",
    "                                     sheet_name = 'Fact and Forecast Wells')\n",
    "    worksheet = writer.sheets['Fact and Forecast Wells']\n",
    "    worksheet.set_column('A:D', 20)\n",
    "    \n",
    "    assets_lateral_length.to_excel(writer, index=False, \n",
    "                                   sheet_name = 'Asset Wells Lateral Length')\n",
    "    worksheet = writer.sheets['Asset Wells Lateral Length']\n",
    "    worksheet.set_column('A:D', 30)\n",
    "    \n",
    "    assets_feet_between_wells.to_excel(writer, index=False, \n",
    "                                       sheet_name = 'Distance Between Asset Wells')\n",
    "    worksheet = writer.sheets['Distance Between Asset Wells']\n",
    "    worksheet.set_column('A:D', 30)\n",
    "    \n",
    "    (assets_lateral_length_feet_between_wells\n",
    "     .to_excel(writer, index=False, sheet_name = 'Lat Length Dist Btw Asset Wells'))\n",
    "    worksheet = writer.sheets['Lat Length Dist Btw Asset Wells']\n",
    "    worksheet.set_column('A:D', 30)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    merge_pdf(production_rig_well_count_file_names, production_rigs_wells_filename, 'basin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_level_analytics_time = round((tm.time() - start_time_to_check), 1)\n",
    "print(f'--- High level basin analysis took {basin_level_analytics_time} seconds ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_level_analysis(initial_dataset, company, basin, \n",
    "                           parameter, start_quarter, end_quarter):\n",
    "    \n",
    "    \"\"\"\n",
    "    initial_dataset is assets_basins_dataset - as default\n",
    "    company - company ticker\n",
    "    basin - BASIN_NAME\n",
    "    parameter - 'type_curve_oil_value' ; 'oil_value' ; 'type_curve_gas_value' ; 'gas_value' ; \n",
    "    'rig_count_value' ; 'well_count_value' ; 'capex_value'\n",
    "    \"\"\"\n",
    "    \n",
    "    df = (initial_dataset[(initial_dataset['ticker'] == company) \n",
    "                          & (initial_dataset['name_basin'] == basin) \n",
    "                          & (initial_dataset['quarter'] >= start_quarter) \n",
    "                          & (initial_dataset['quarter'] <= end_quarter)])\n",
    "    assets = list(df.name.unique())\n",
    "\n",
    "    if parameter == 'type_curve_oil_value' or parameter == 'type_curve_gas_value':\n",
    "        dataset_parameter = df[(df[parameter] > 0) & (df['name'] == assets[0])][['quarter']]\n",
    "        \n",
    "        for asset in assets:\n",
    "            if df[df['name'] == asset][parameter].sum() == 0:\n",
    "                dataset_parameter[asset] = np.nan\n",
    "            else:\n",
    "                dataset_parameter[asset] = (df[(df[parameter] > 0) \n",
    "                                               & (df['name'] == asset)][parameter].values)\n",
    "                dataset_parameter['quarter'] = (df[(df[parameter] > 0) \n",
    "                                                   & (df['name'] == asset)]['quarter'].values)\n",
    "            \n",
    "    else:\n",
    "        dataset_parameter = df[(df['name'] == assets[0])][['quarter']]\n",
    "        \n",
    "        for asset in assets:\n",
    "            dataset_parameter[asset] = df[(df['name'] == asset)][parameter].values\n",
    "        \n",
    "    return dataset_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_to_check_company = tm.time()\n",
    "\n",
    "company_lateral_length = lateral_length_feet_between_wells(asset_data_df, \n",
    "                                                           assets_basins_dataset, \n",
    "                                                           11, BASIN_NAME, 'company_level')\n",
    "company_feet_between_wells = lateral_length_feet_between_wells(asset_data_df, \n",
    "                                                               assets_basins_dataset, \n",
    "                                                               12, BASIN_NAME, 'company_level')\n",
    "company_assets_lateral_length_feet_between_wells = (company_lateral_length\n",
    "                                                    .merge(company_feet_between_wells, \n",
    "                                                           left_on=['asset_name'], \n",
    "                                                           right_on=['asset_name'], \n",
    "                                                           how='inner')\n",
    "                                                    .rename(columns={\n",
    "                                                        'value_x':'Lateral length, ft', \n",
    "                                                        'value_y':'Feet between wells, ft', \n",
    "                                                        'ticker_x':'Company', \n",
    "                                                        'name_x':'asset'})\n",
    "                                                    [['Company', 'asset', \n",
    "                                                      'Lateral length, ft', \n",
    "                                                      'Feet between wells, ft']])\n",
    "\n",
    "for company in list(capex_per_company.Company):\n",
    "    \n",
    "    company_file_names = []\n",
    "    \n",
    "    type_curve_oil = company_level_analysis(assets_basins_dataset, company, BASIN_NAME, \n",
    "                                            'type_curve_oil_value', START_QUARTER_ACTUAL, 20234)\n",
    "\n",
    "    export_company_to_s3(company, 'line', f'{company}_{BASIN_NAME}_Oil_Type_Curve_{TODAY}', \n",
    "                 type_curve_oil, '', f'{company} - {BASIN_NAME} Oil Type Curve', 'oil')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Oil Type Curve.pdf')\n",
    "    \n",
    "    oil_production = company_level_analysis(assets_basins_dataset, company, \n",
    "                                            BASIN_NAME, 'oil_value', \n",
    "                                            START_QUARTER_ACTUAL, END_QUARTER_FORECAST)\n",
    "    \n",
    "    export_company_to_s3(company, 'stacked', f'{company}_{BASIN_NAME}_Oil_Production_{TODAY}', \n",
    "                     oil_production, '', f'{company} - {BASIN_NAME} Oil Production', 'oil')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Oil Production.pdf')\n",
    "\n",
    "    type_curve_gas = company_level_analysis(assets_basins_dataset, company, BASIN_NAME, \n",
    "                                            'type_curve_gas_value', START_QUARTER_ACTUAL, 20234)\n",
    "    \n",
    "    export_company_to_s3(company, 'line', f'{company}_{BASIN_NAME}_Gas_Type_Curve_{TODAY}', \n",
    "                 type_curve_gas, '', f'{company} - {BASIN_NAME} Gas Type Curve', 'gas')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Gas Type Curve.pdf')\n",
    "\n",
    "    gas_production = company_level_analysis(assets_basins_dataset, company, \n",
    "                                            BASIN_NAME, 'gas_value', \n",
    "                                            START_QUARTER_ACTUAL, END_QUARTER_FORECAST)\n",
    "    \n",
    "    export_company_to_s3(company, 'stacked', f'{company}_{BASIN_NAME}_Gas_Production_{TODAY}', \n",
    "                     gas_production, '', f'{company} - {BASIN_NAME} Gas Production', 'gas')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Gas Production.pdf')\n",
    "\n",
    "    rig_count = (company_level_analysis(assets_basins_dataset, company, \n",
    "                                        BASIN_NAME, 'rig_count_value', \n",
    "                                        START_QUARTER_ACTUAL, END_QUARTER_FORECAST))\n",
    "    \n",
    "    export_company_to_s3(company, 'stacked_bar', f'{company}_{BASIN_NAME}_Active_Rigs_{TODAY}', \n",
    "                     rig_count, '', f'{company} - {BASIN_NAME} Active Rigs', 'rig')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Active Rigs.pdf')\n",
    "\n",
    "    well_count_value = (company_level_analysis(assets_basins_dataset, company, \n",
    "                                               BASIN_NAME, 'well_count_value', \n",
    "                                               START_QUARTER_ACTUAL, END_QUARTER_FORECAST))\n",
    "    \n",
    "    export_company_to_s3(company, 'stacked_bar', \n",
    "                         f'{company}_{BASIN_NAME}_New_Wells_Brought_Online_{TODAY}', \n",
    "                         well_count_value, '', \n",
    "                         f'{company} - {BASIN_NAME} New Wells Brought Online', 'well')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} New Wells Brought Online.pdf')\n",
    "\n",
    "    capex_value = (company_level_analysis(assets_basins_dataset, company, \n",
    "                                          BASIN_NAME, 'capex_value', \n",
    "                                          START_QUARTER_ACTUAL, END_QUARTER_FORECAST))\n",
    "    \n",
    "    export_company_to_s3(company, 'stacked_bar', f'{company}_{BASIN_NAME}_Capex_{TODAY}', \n",
    "                     capex_value, '', f'{company} - {BASIN_NAME} Capex', 'capex')\n",
    "    company_file_names.append(f'{company} - {BASIN_NAME} Capex.pdf')\n",
    "\n",
    "    company_level_filename = f'{company} - {BASIN_NAME} Analysis {TODAY}'\n",
    "    \n",
    "    lat_length_feet_distance = (company_assets_lateral_length_feet_between_wells[\n",
    "        company_assets_lateral_length_feet_between_wells['Company'] == company]\n",
    "                                [['asset', 'Lateral length, ft', 'Feet between wells, ft']])\n",
    "    \n",
    "    export_company_to_s3(company, \n",
    "                         'horizontal_grouped', \n",
    "                         f'{company}_{BASIN_NAME}_Lateral_Length_and_Feet_Between_Wells_{TODAY}', \n",
    "                         lat_length_feet_distance, '', \n",
    "                         f'{company} - {BASIN_NAME} Lateral Length and Feet Between Wells')\n",
    "    (company_file_names\n",
    "     .append(f'{company} - {BASIN_NAME} Lateral Length and Feet Between Wells.pdf'))\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        merge_pdf(company_file_names, company_level_filename, 'company', company)\n",
    "\n",
    "    with pd.ExcelWriter(f'{path}/{BASIN_NAME}/{company}/DATA - {company} - {BASIN_NAME} Analysis.xlsx', \n",
    "                        engine = 'xlsxwriter') as writer:\n",
    "\n",
    "        type_curve_oil.to_excel(writer, index=False, sheet_name='Oil Type Curve')\n",
    "        worksheet = writer.sheets['Oil Type Curve']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        oil_production.to_excel(writer, index=False, sheet_name = 'Oil Production')\n",
    "        worksheet = writer.sheets['Oil Production']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        type_curve_gas.to_excel(writer, index=False, sheet_name = 'Gas Type Curve')\n",
    "        worksheet = writer.sheets['Gas Type Curve']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        gas_production.to_excel(writer, index=False, sheet_name = 'Gas Production')\n",
    "        worksheet = writer.sheets['Gas Production']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        rig_count.to_excel(writer, index=False, sheet_name = 'Active Rigs')\n",
    "        worksheet = writer.sheets['Active Rigs']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        well_count_value.to_excel(writer, index=False, sheet_name = 'New Wells Brought Online')\n",
    "        worksheet = writer.sheets['New Wells Brought Online']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        capex_value.to_excel(writer, index=False, sheet_name = 'Capex ($MM)')\n",
    "        worksheet = writer.sheets['Capex ($MM)']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "        \n",
    "        lat_length_feet_distance.to_excel(writer, index=False, sheet_name = 'Lat Length Dist Btw Asset Wells')\n",
    "        worksheet = writer.sheets['Lat Length Dist Btw Asset Wells']\n",
    "        worksheet.set_column('A:BA', 25)\n",
    "\n",
    "        writer.save()\n",
    "\n",
    "company_level_analytics_time = round((tm.time() - start_time_to_check_company), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'--- High level basin analysis took {basin_level_analytics_time} seconds ---')\n",
    "print(f'--- Company level analysis took {company_level_analytics_time} seconds ---')\n",
    "print(f'--- Total time for analysis {basin_level_analytics_time + company_level_analytics_time} seconds ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
